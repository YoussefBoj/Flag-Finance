{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 06: RAG + LLM Integration for Explainable Fraud Detection\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook adds an **explainability layer** to our fraud detection system using:\n",
        "1. **Retrieval-Augmented Generation (RAG)** for case-based reasoning\n",
        "2. **Large Language Models (LLMs)** for natural language explanations\n",
        "3. **Vector databases** for storing fraud case studies\n",
        "\n",
        "### Architecture\n",
        "\n",
        "```\n",
        "New Transaction\n",
        "       ↓\n",
        "Fusion Model Prediction (fraud/legit)\n",
        "       ↓\n",
        "Extract Features & Embedding\n",
        "       ↓\n",
        "Vector Database Search (FAISS)\n",
        "   → Find Similar Cases\n",
        "       ↓\n",
        "LLM Prompt Engineering\n",
        "   → Context: Similar cases\n",
        "   → Transaction details\n",
        "   → Model prediction\n",
        "       ↓\n",
        "Natural Language Explanation\n",
        "```\n",
        "\n",
        "### Key Features\n",
        "\n",
        "- **Case-based reasoning**: Find similar historical fraud cases\n",
        "- **Multi-modal explanations**: Combine graph, sequence, and transaction features\n",
        "- **LLM integration**: OpenAI GPT, HuggingFace models, or local LLMs\n",
        "- **Evaluation metrics**: BLEU, ROUGE, BERTScore for explanation quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Environment detection and setup\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "RUNNING_ON_KAGGLE = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
        "\n",
        "print(f\"🔍 Running on Kaggle: {RUNNING_ON_KAGGLE}\")\n",
        "print(f\"🐍 Python version: {sys.version}\")\n",
        "\n",
        "# Install required packages\n",
        "if RUNNING_ON_KAGGLE:\n",
        "    print(\"📦 Installing RAG dependencies...\")\n",
        "    # !pip install -q langchain openai faiss-cpu sentence-transformers\n",
        "    # !pip install -q chromadb tiktoken\n",
        "else:\n",
        "    print(\"📦 Local environment - ensure dependencies installed\")\n",
        "\n",
        "print(\"✅ Environment setup complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import pickle\n",
        "import warnings\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import time\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# RAG and LLM libraries\n",
        "try:\n",
        "    from langchain.embeddings import HuggingFaceEmbeddings\n",
        "    from langchain.vectorstores import FAISS, Chroma\n",
        "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "    from langchain.docstore.document import Document\n",
        "    from langchain.llms import OpenAI, HuggingFacePipeline\n",
        "    from langchain.chains import RetrievalQA\n",
        "    from langchain.prompts import PromptTemplate\n",
        "    RAG_AVAILABLE = True\n",
        "    print('✅ LangChain imports successful')\n",
        "except ImportError:\n",
        "    RAG_AVAILABLE = False\n",
        "    print('⚠️ LangChain not available - install with: pip install langchain')\n",
        "\n",
        "try:\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    SBERT_AVAILABLE = True\n",
        "    print('✅ Sentence Transformers available')\n",
        "except ImportError:\n",
        "    SBERT_AVAILABLE = False\n",
        "    print('⚠️ Sentence Transformers not available')\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "print(f'\\nPyTorch version: {torch.__version__}')\n",
        "print(f'CUDA available: {torch.cuda.is_available()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Path Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure paths\n",
        "if RUNNING_ON_KAGGLE:\n",
        "    BASE_PATH = Path('/kaggle/input/flag-finance')\n",
        "    WORKING_ROOT = Path('/kaggle/working')\n",
        "    \n",
        "    PROCESSED_PATH = BASE_PATH / 'processed' / 'processed'\n",
        "    MODELS_PATH = BASE_PATH / 'fusion-models'\n",
        "    \n",
        "    OUTPUT_PATH = WORKING_ROOT / 'rag_output'\n",
        "    VECTOR_DB_PATH = WORKING_ROOT / 'vector_db'\n",
        "else:\n",
        "    BASE_PATH = Path('..').resolve()\n",
        "    WORKING_ROOT = BASE_PATH\n",
        "    \n",
        "    DATA_PATH = BASE_PATH / 'data'\n",
        "    PROCESSED_PATH = DATA_PATH / 'processed'\n",
        "    MODELS_PATH = DATA_PATH / 'models'\n",
        "    \n",
        "    OUTPUT_PATH = DATA_PATH / 'rag_output'\n",
        "    VECTOR_DB_PATH = DATA_PATH / 'vector_db'\n",
        "\n",
        "OUTPUT_PATH.mkdir(exist_ok=True, parents=True)\n",
        "VECTOR_DB_PATH.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "print(f'📁 Path Configuration:')\n",
        "print(f'   Processed data: {PROCESSED_PATH}')\n",
        "print(f'   Models: {MODELS_PATH}')\n",
        "print(f'   Output: {OUTPUT_PATH}')\n",
        "print(f'   Vector DB: {VECTOR_DB_PATH}')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'\\n🔧 Device: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Transaction Data and Model Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('='*70)\n",
        "print('LOADING DATA AND PREDICTIONS')\n",
        "print('='*70)\n",
        "\n",
        "# Load transaction data\n",
        "paysim_file = PROCESSED_PATH / 'paysim_sample_enhanced.csv'\n",
        "if not paysim_file.exists():\n",
        "    paysim_file = PROCESSED_PATH / 'paysim_data_enhanced.csv'\n",
        "\n",
        "if paysim_file.exists():\n",
        "    df = pd.read_csv(paysim_file)\n",
        "    print(f'\\n✅ Loaded transaction data: {df.shape}')\n",
        "    print(f'   Columns: {list(df.columns)}')\n",
        "else:\n",
        "    raise FileNotFoundError(f'Transaction data not found at {paysim_file}')\n",
        "\n",
        "# Load fusion model results\n",
        "fusion_results_file = OUTPUT_PATH / 'fusion_results.json'\n",
        "if not fusion_results_file.exists():\n",
        "    fusion_results_file = MODELS_PATH / 'fusion_results.json'\n",
        "\n",
        "if fusion_results_file.exists():\n",
        "    with open(fusion_results_file, 'r') as f:\n",
        "        fusion_results = json.load(f)\n",
        "    print(f'\\n✅ Loaded fusion results')\n",
        "    print(f'   Best model: {fusion_results[\"best_fusion_model\"][\"name\"]}')\n",
        "else:\n",
        "    print(f'\\n⚠️ Fusion results not found - will use sample predictions')\n",
        "    fusion_results = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Fraud Case Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_fraud_case_descriptions(df: pd.DataFrame, max_cases: int = 1000) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Create detailed textual descriptions of fraud cases.\n",
        "    These will be stored in the vector database for retrieval.\n",
        "    \"\"\"\n",
        "    print(f'\\n📝 Creating fraud case descriptions...')\n",
        "    \n",
        "    # Get fraud cases\n",
        "    fraud_cases = df[df['isFraud'] == 1].copy()\n",
        "    \n",
        "    if len(fraud_cases) > max_cases:\n",
        "        fraud_cases = fraud_cases.sample(n=max_cases, random_state=42)\n",
        "    \n",
        "    print(f'   Processing {len(fraud_cases)} fraud cases...')\n",
        "    \n",
        "    case_documents = []\n",
        "    \n",
        "    for idx, row in tqdm(fraud_cases.iterrows(), total=len(fraud_cases), desc='Creating cases'):\n",
        "        # Create detailed description\n",
        "        description = f\"\"\"\n",
        "FRAUD CASE #{idx}\n",
        "\n",
        "Transaction Details:\n",
        "- Type: {row.get('type', 'UNKNOWN')}\n",
        "- Amount: ${row.get('amount', 0):,.2f}\n",
        "- Time: Step {row.get('step', 0)} (Hour {row.get('hour', 0) if 'hour' in row.columns else 'N/A'})\n",
        "- Weekend: {'Yes' if row.get('is_weekend', 0) == 1 else 'No'}\n",
        "\n",
        "Account Balances:\n",
        "- Origin Old Balance: ${row.get('oldbalanceOrg', 0):,.2f}\n",
        "- Origin New Balance: ${row.get('newbalanceOrig', 0):,.2f}\n",
        "- Destination Old Balance: ${row.get('oldbalanceDest', 0):,.2f}\n",
        "- Destination New Balance: ${row.get('newbalanceDest', 0):,.2f}\n",
        "\n",
        "Fraud Indicators:\n",
        "- Balance Error (Origin): ${abs(row.get('balance_error_orig', 0)):,.2f}\n",
        "- Balance Error (Dest): ${abs(row.get('balance_error_dest', 0)):,.2f}\n",
        "- Flagged by System: {'Yes' if row.get('isFlaggedFraud', 0) == 1 else 'No'}\n",
        "\n",
        "Pattern Analysis:\n",
        "- High amount transfer with balance inconsistencies\n",
        "- Suspicious account behavior detected\n",
        "- Transaction type: {row.get('type', 'UNKNOWN')}\n",
        "\"\"\"\n",
        "        \n",
        "        case_documents.append({\n",
        "            'case_id': str(idx),\n",
        "            'description': description.strip(),\n",
        "            'transaction_type': row.get('type', 'UNKNOWN'),\n",
        "            'amount': float(row.get('amount', 0)),\n",
        "            'metadata': {\n",
        "                'step': int(row.get('step', 0)),\n",
        "                'type': str(row.get('type', 'UNKNOWN')),\n",
        "                'amount': float(row.get('amount', 0))\n",
        "            }\n",
        "        })\n",
        "    \n",
        "    print(f'\\n✅ Created {len(case_documents)} fraud case descriptions')\n",
        "    return case_documents\n",
        "\n",
        "# Create case database\n",
        "fraud_cases = create_fraud_case_descriptions(df, max_cases=500)\n",
        "\n",
        "# Save to JSON\n",
        "cases_file = OUTPUT_PATH / 'fraud_cases_database.json'\n",
        "with open(cases_file, 'w') as f:\n",
        "    json.dump(fraud_cases, f, indent=2)\n",
        "\n",
        "print(f'\\n💾 Saved fraud cases to: {cases_file}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build Vector Database for RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not RAG_AVAILABLE or not SBERT_AVAILABLE:\n",
        "    print('⚠️ RAG libraries not available. Skipping vector database creation.')\n",
        "    print('Install with: pip install langchain sentence-transformers faiss-cpu')\n",
        "else:\n",
        "    print('='*70)\n",
        "    print('BUILDING VECTOR DATABASE')\n",
        "    print('='*70)\n",
        "    \n",
        "    # Initialize embedding model\n",
        "    print('\\n📦 Loading embedding model...')\n",
        "    embedding_model = HuggingFaceEmbeddings(\n",
        "        model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
        "        model_kwargs={'device': 'cuda' if torch.cuda.is_available() else 'cpu'}\n",
        "    )\n",
        "    print('✅ Embedding model loaded')\n",
        "    \n",
        "    # Create documents for vector store\n",
        "    documents = [\n",
        "        Document(\n",
        "            page_content=case['description'],\n",
        "            metadata=case['metadata']\n",
        "        )\n",
        "        for case in fraud_cases\n",
        "    ]\n",
        "    \n",
        "    print(f'\\n🔨 Building FAISS vector database with {len(documents)} documents...')\n",
        "    \n",
        "    # Build vector store\n",
        "    vector_store = FAISS.from_documents(\n",
        "        documents=documents,\n",
        "        embedding=embedding_model\n",
        "    )\n",
        "    \n",
        "    # Save vector store\n",
        "    vector_store.save_local(str(VECTOR_DB_PATH / 'fraud_cases_faiss'))\n",
        "    \n",
        "    print(f'✅ Vector database created and saved to: {VECTOR_DB_PATH}')\n",
        "    print(f'   Total vectors: {len(documents)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Retrieval System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FraudCaseRetriever:\n",
        "    \"\"\"Retrieve similar fraud cases for explanation.\"\"\"\n",
        "    \n",
        "    def __init__(self, vector_store_path: Path, embedding_model):\n",
        "        self.vector_store = FAISS.load_local(\n",
        "            str(vector_store_path),\n",
        "            embeddings=embedding_model\n",
        "        )\n",
        "        self.retriever = self.vector_store.as_retriever(\n",
        "            search_kwargs={'k': 3}  # Retrieve top 3 similar cases\n",
        "        )\n",
        "    \n",
        "    def retrieve_similar_cases(self, query: str, k: int = 3) -> List[Document]:\n",
        "        \"\"\"Retrieve k most similar fraud cases.\"\"\"\n",
        "        return self.vector_store.similarity_search(query, k=k)\n",
        "    \n",
        "    def create_query_from_transaction(self, transaction: Dict) -> str:\n",
        "        \"\"\"Create search query from transaction features.\"\"\"\n",
        "        query = f\"\"\"\n",
        "Transaction type: {transaction.get('type', 'UNKNOWN')}\n",
        "Amount: ${transaction.get('amount', 0):,.2f}\n",
        "Balance inconsistencies detected\n",
        "Suspicious account behavior\n",
        "\"\"\"\n",
        "        return query.strip()\n",
        "\n",
        "if RAG_AVAILABLE and SBERT_AVAILABLE:\n",
        "    # Initialize retriever\n",
        "    retriever = FraudCaseRetriever(\n",
        "        vector_store_path=VECTOR_DB_PATH / 'fraud_cases_faiss',\n",
        "        embedding_model=embedding_model\n",
        "    )\n",
        "    print('✅ Fraud case retriever initialized')\n",
        "else:\n",
        "    retriever = None\n",
        "    print('⚠️ Retriever not available (missing dependencies)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LLM Prompt Templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "FRAUD_EXPLANATION_TEMPLATE = \"\"\"\n",
        "You are an expert fraud analyst explaining why a transaction was flagged as fraudulent.\n",
        "\n",
        "CURRENT TRANSACTION:\n",
        "{transaction_details}\n",
        "\n",
        "MODEL PREDICTION:\n",
        "- Fraud Probability: {fraud_probability:.2%}\n",
        "- Prediction: {prediction}\n",
        "- Confidence: {confidence}\n",
        "\n",
        "SIMILAR HISTORICAL FRAUD CASES:\n",
        "{similar_cases}\n",
        "\n",
        "TASK:\n",
        "Provide a clear, professional explanation of why this transaction was flagged as fraud.\n",
        "Include:\n",
        "1. Key suspicious indicators\n",
        "2. Comparison with similar fraud cases\n",
        "3. Risk factors and patterns\n",
        "4. Recommended action\n",
        "\n",
        "Keep the explanation concise (3-4 sentences) and actionable.\n",
        "\n",
        "EXPLANATION:\n",
        "\"\"\"\n",
        "\n",
        "LEGIT_EXPLANATION_TEMPLATE = \"\"\"\n",
        "You are an expert fraud analyst explaining why a transaction was classified as legitimate.\n",
        "\n",
        "CURRENT TRANSACTION:\n",
        "{transaction_details}\n",
        "\n",
        "MODEL PREDICTION:\n",
        "- Fraud Probability: {fraud_probability:.2%}\n",
        "- Prediction: {prediction}\n",
        "- Confidence: {confidence}\n",
        "\n",
        "TASK:\n",
        "Provide a brief explanation of why this transaction appears legitimate.\n",
        "Include:\n",
        "1. Normal transaction indicators\n",
        "2. Why it doesn't match fraud patterns\n",
        "3. Confidence assessment\n",
        "\n",
        "Keep the explanation concise (2-3 sentences).\n",
        "\n",
        "EXPLANATION:\n",
        "\"\"\"\n",
        "\n",
        "print('✅ Prompt templates defined')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explanation Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FraudExplainer:\n",
        "    \"\"\"Generate natural language explanations for fraud predictions.\"\"\"\n",
        "    \n",
        "    def __init__(self, retriever=None, use_llm: bool = False, api_key: Optional[str] = None):\n",
        "        self.retriever = retriever\n",
        "        self.use_llm = use_llm\n",
        "        self.llm = None\n",
        "        \n",
        "        if use_llm and api_key:\n",
        "            try:\n",
        "                from langchain.llms import OpenAI\n",
        "                self.llm = OpenAI(temperature=0.3, api_key=api_key)\n",
        "                print('✅ LLM initialized')\n",
        "            except Exception as e:\n",
        "                print(f'⚠️ LLM initialization failed: {e}')\n",
        "                self.use_llm = False\n",
        "    \n",
        "    def _template_legit_explanation(self, transaction: Dict, prob: float) -> str:\n",
        "        \"\"\"Template-based legitimate explanation.\"\"\"\n",
        "        \n",
        "        amount = transaction.get('amount', 0)\n",
        "        tx_type = transaction.get('type', 'UNKNOWN')\n",
        "        \n",
        "        explanation = f\"This {tx_type} transaction of ${amount:,.2f} appears legitimate \"\n",
        "        explanation += f\"with {(1-prob):.1%} confidence. \"\n",
        "        \n",
        "        explanation += \"The transaction shows normal patterns with consistent account balances \"\n",
        "        explanation += \"and no suspicious indicators. No further action required.\"\n",
        "        \n",
        "        return explanation\n",
        "\n",
        "# Initialize explainer\n",
        "explainer = FraudExplainer(\n",
        "    retriever=retriever if RAG_AVAILABLE else None,\n",
        "    use_llm=False  # Set to True and provide API key to use LLM\n",
        ")\n",
        "\n",
        "print('✅ Fraud explainer initialized')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Explainer on Sample Transactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('='*70)\n",
        "print('TESTING EXPLAINER ON SAMPLE TRANSACTIONS')\n",
        "print('='*70)\n",
        "\n",
        "# Get sample fraud cases\n",
        "fraud_samples = df[df['isFraud'] == 1].sample(n=3, random_state=42)\n",
        "legit_samples = df[df['isFraud'] == 0].sample(n=2, random_state=42)\n",
        "\n",
        "test_samples = pd.concat([fraud_samples, legit_samples])\n",
        "\n",
        "print(f'\\nGenerating explanations for {len(test_samples)} transactions...\\n')\n",
        "\n",
        "explanations = []\n",
        "\n",
        "for idx, row in test_samples.iterrows():\n",
        "    transaction = row.to_dict()\n",
        "    true_label = int(row['isFraud'])\n",
        "    \n",
        "    # Simulate model prediction (use actual prediction if available)\n",
        "    fraud_prob = 0.85 if true_label == 1 else 0.15\n",
        "    prediction = 1 if fraud_prob > 0.5 else 0\n",
        "    \n",
        "    # Generate explanation\n",
        "    explanation = explainer.explain_prediction(\n",
        "        transaction=transaction,\n",
        "        prediction=prediction,\n",
        "        fraud_probability=fraud_prob\n",
        "    )\n",
        "    \n",
        "    explanations.append({\n",
        "        'transaction_id': idx,\n",
        "        'true_label': 'FRAUD' if true_label == 1 else 'LEGIT',\n",
        "        'prediction': 'FRAUD' if prediction == 1 else 'LEGIT',\n",
        "        'fraud_probability': fraud_prob,\n",
        "        'amount': float(transaction.get('amount', 0)),\n",
        "        'type': transaction.get('type', 'UNKNOWN'),\n",
        "        'explanation': explanation\n",
        "    })\n",
        "    \n",
        "    print(f\"Transaction #{idx} ({transaction.get('type', 'UNKNOWN')} ${transaction.get('amount', 0):,.2f})\")\n",
        "    print(f\"True Label: {true_label} | Prediction: {prediction} | Prob: {fraud_prob:.2%}\")\n",
        "    print(f\"Explanation: {explanation}\")\n",
        "    print('-'*70)\n",
        "\n",
        "# Save explanations\n",
        "explanations_file = OUTPUT_PATH / 'sample_explanations.json'\n",
        "with open(explanations_file, 'w') as f:\n",
        "    json.dump(explanations, f, indent=2)\n",
        "\n",
        "print(f'\\n💾 Saved explanations to: {explanations_file}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Batch Explanation Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_batch_explanations(df: pd.DataFrame, \n",
        "                               explainer: FraudExplainer,\n",
        "                               max_samples: int = 100) -> pd.DataFrame:\n",
        "    \"\"\"Generate explanations for a batch of transactions.\"\"\"\n",
        "    \n",
        "    print(f'\\n📊 Generating explanations for {max_samples} transactions...')\n",
        "    \n",
        "    # Sample transactions\n",
        "    sample_df = df.sample(n=min(max_samples, len(df)), random_state=42).copy()\n",
        "    \n",
        "    explanations = []\n",
        "    \n",
        "    for idx, row in tqdm(sample_df.iterrows(), total=len(sample_df), desc='Generating'):\n",
        "        transaction = row.to_dict()\n",
        "        true_label = int(row['isFraud'])\n",
        "        \n",
        "        # Simulate prediction\n",
        "        fraud_prob = 0.8 if true_label == 1 else 0.2\n",
        "        prediction = 1 if fraud_prob > 0.5 else 0\n",
        "        \n",
        "        explanation = explainer.explain_prediction(\n",
        "            transaction=transaction,\n",
        "            prediction=prediction,\n",
        "            fraud_probability=fraud_prob\n",
        "        )\n",
        "        \n",
        "        explanations.append(explanation)\n",
        "    \n",
        "    sample_df['explanation'] = explanations\n",
        "    sample_df['fraud_probability'] = sample_df['isFraud'].apply(\n",
        "        lambda x: 0.8 if x == 1 else 0.2\n",
        "    )\n",
        "    \n",
        "    return sample_df\n",
        "\n",
        "# Generate batch explanations\n",
        "explained_df = generate_batch_explanations(df, explainer, max_samples=50)\n",
        "\n",
        "# Save results\n",
        "explained_file = OUTPUT_PATH / 'transactions_with_explanations.csv'\n",
        "explained_df.to_csv(explained_file, index=False)\n",
        "\n",
        "print(f'\\n✅ Saved explained transactions to: {explained_file}')\n",
        "print(f'   Total transactions: {len(explained_df)}')\n",
        "print(f'   With explanations: {explained_df[\"explanation\"].notna().sum()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explanation Quality Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('='*70)\n",
        "print('EXPLANATION QUALITY ANALYSIS')\n",
        "print('='*70)\n",
        "\n",
        "# Analyze explanation statistics\n",
        "explanation_stats = {\n",
        "    'total_explanations': len(explained_df),\n",
        "    'fraud_explanations': len(explained_df[explained_df['isFraud'] == 1]),\n",
        "    'legit_explanations': len(explained_df[explained_df['isFraud'] == 0]),\n",
        "    'avg_explanation_length': explained_df['explanation'].str.len().mean(),\n",
        "    'min_length': explained_df['explanation'].str.len().min(),\n",
        "    'max_length': explained_df['explanation'].str.len().max()\n",
        "}\n",
        "\n",
        "print(f'\\n📊 Explanation Statistics:')\n",
        "for key, value in explanation_stats.items():\n",
        "    print(f'   {key}: {value}')\n",
        "\n",
        "# Visualize explanation length distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Explanation length by label\n",
        "explained_df['explanation_length'] = explained_df['explanation'].str.len()\n",
        "\n",
        "fraud_lengths = explained_df[explained_df['isFraud'] == 1]['explanation_length']\n",
        "legit_lengths = explained_df[explained_df['isFraud'] == 0]['explanation_length']\n",
        "\n",
        "axes[0].hist([fraud_lengths, legit_lengths], label=['Fraud', 'Legit'], bins=20, alpha=0.7)\n",
        "axes[0].set_xlabel('Explanation Length (characters)')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "axes[0].set_title('Explanation Length Distribution', fontweight='bold')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Sample explanations word cloud data\n",
        "fraud_words = ' '.join(explained_df[explained_df['isFraud'] == 1]['explanation'])\n",
        "word_freq = pd.Series(fraud_words.split()).value_counts().head(10)\n",
        "\n",
        "axes[1].barh(word_freq.index, word_freq.values, color='steelblue', alpha=0.8)\n",
        "axes[1].set_xlabel('Frequency')\n",
        "axes[1].set_title('Most Common Words in Fraud Explanations', fontweight='bold')\n",
        "axes[1].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_PATH / 'explanation_analysis.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f'\\n✅ Saved visualization to: {OUTPUT_PATH / \"explanation_analysis.png\"}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Interactive Explanation Dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_explanation_report(explained_df: pd.DataFrame, output_path: Path):\n",
        "    \"\"\"Create HTML report with explanations.\"\"\"\n",
        "    \n",
        "    html_template = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Fraud Detection Explanations</title>\n",
        "    <style>\n",
        "        body {{ font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }}\n",
        "        .container {{ max-width: 1200px; margin: auto; background: white; padding: 30px; border-radius: 10px; }}\n",
        "        h1 {{ color: #2c3e50; text-align: center; }}\n",
        "        .transaction {{ border: 2px solid #ecf0f1; margin: 20px 0; padding: 20px; border-radius: 8px; }}\n",
        "        .fraud {{ border-color: #e74c3c; background-color: #fadbd8; }}\n",
        "        .legit {{ border-color: #27ae60; background-color: #d5f4e6; }}\n",
        "        .header {{ font-size: 18px; font-weight: bold; margin-bottom: 10px; }}\n",
        "        .details {{ font-size: 14px; color: #555; margin: 5px 0; }}\n",
        "        .explanation {{ background-color: #f9f9f9; padding: 15px; margin-top: 10px; border-left: 4px solid #3498db; font-style: italic; }}\n",
        "        .stats {{ background-color: #3498db; color: white; padding: 20px; border-radius: 8px; margin-bottom: 30px; }}\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"container\">\n",
        "        <h1>🔍 Fraud Detection Explanation Report</h1>\n",
        "        \n",
        "        <div class=\"stats\">\n",
        "            <h2>Summary Statistics</h2>\n",
        "            <p><strong>Total Transactions:</strong> {total}</p>\n",
        "            <p><strong>Fraud Cases:</strong> {fraud_count} ({fraud_pct:.1f}%)</p>\n",
        "            <p><strong>Legitimate Cases:</strong> {legit_count} ({legit_pct:.1f}%)</p>\n",
        "        </div>\n",
        "        \n",
        "        <h2>Transaction Explanations</h2>\n",
        "        {transactions}\n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "    \n",
        "    # Generate transaction HTML blocks\n",
        "    transactions_html = \"\"\n",
        "    \n",
        "    for idx, row in explained_df.head(20).iterrows():\n",
        "        is_fraud = row['isFraud'] == 1\n",
        "        css_class = 'fraud' if is_fraud else 'legit'\n",
        "        label = 'FRAUD' if is_fraud else 'LEGITIMATE'\n",
        "        \n",
        "        transaction_html = f\"\"\"\n",
        "        <div class=\"transaction {css_class}\">\n",
        "            <div class=\"header\">Transaction #{idx} - {label}</div>\n",
        "            <div class=\"details\"><strong>Type:</strong> {row['type']}</div>\n",
        "            <div class=\"details\"><strong>Amount:</strong> ${row['amount']:,.2f}</div>\n",
        "            <div class=\"details\"><strong>Fraud Probability:</strong> {row['fraud_probability']:.1%}</div>\n",
        "            <div class=\"explanation\">\n",
        "                <strong>Explanation:</strong><br>\n",
        "                {row['explanation']}\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        transactions_html += transaction_html\n",
        "    \n",
        "    # Fill template\n",
        "    fraud_count = len(explained_df[explained_df['isFraud'] == 1])\n",
        "    legit_count = len(explained_df[explained_df['isFraud'] == 0])\n",
        "    total = len(explained_df)\n",
        "    \n",
        "    html_content = html_template.format(\n",
        "        total=total,\n",
        "        fraud_count=fraud_count,\n",
        "        fraud_pct=fraud_count/total*100,\n",
        "        legit_count=legit_count,\n",
        "        legit_pct=legit_count/total*100,\n",
        "        transactions=transactions_html\n",
        "    )\n",
        "    \n",
        "    # Save HTML\n",
        "    report_file = output_path / 'explanation_report.html'\n",
        "    with open(report_file, 'w') as f:\n",
        "        f.write(html_content)\n",
        "    \n",
        "    print(f'✅ Created HTML report: {report_file}')\n",
        "    return report_file\n",
        "\n",
        "# Generate report\n",
        "report_path = create_explanation_report(explained_df, OUTPUT_PATH)\n",
        "\n",
        "print(f'\\n📄 Open the report in your browser: {report_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Final Results and Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive results summary\n",
        "rag_results = {\n",
        "    'system_info': {\n",
        "        'vector_database': 'FAISS',\n",
        "        'embedding_model': 'sentence-transformers/all-MiniLM-L6-v2',\n",
        "        'total_fraud_cases': len(fraud_cases),\n",
        "        'llm_enabled': explainer.use_llm,\n",
        "        'retrieval_enabled': retriever is not None\n",
        "    },\n",
        "    'explanation_stats': explanation_stats,\n",
        "    'output_files': {\n",
        "        'fraud_cases_db': str(cases_file),\n",
        "        'vector_db': str(VECTOR_DB_PATH / 'fraud_cases_faiss'),\n",
        "        'explanations': str(explanations_file),\n",
        "        'batch_results': str(explained_file),\n",
        "        'html_report': str(report_path)\n",
        "    },\n",
        "    'sample_explanations': explanations[:5]  # Store first 5 examples\n",
        "}\n",
        "\n",
        "# Save results\n",
        "results_file = OUTPUT_PATH / 'rag_llm_results.json'\n",
        "with open(results_file, 'w') as f:\n",
        "    json.dump(rag_results, f, indent=2)\n",
        "\n",
        "print(f'\\n💾 Saved RAG results to: {results_file}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('='*70)\n",
        "print('🎉 RAG + LLM INTEGRATION COMPLETE')\n",
        "print('='*70)\n",
        "\n",
        "print(f'\\n📊 System Components:')\n",
        "print(f'   ✅ Vector Database: {len(fraud_cases)} fraud cases indexed')\n",
        "print(f'   ✅ Embedding Model: sentence-transformers/all-MiniLM-L6-v2')\n",
        "print(f'   ✅ Retrieval System: {'Active' if retriever else 'Not available'}')\n",
        "print(f'   ✅ LLM Integration: {'Active' if explainer.use_llm else 'Template-based'}')\n",
        "\n",
        "print(f'\\n📁 Generated Outputs:')\n",
        "print(f'   ✅ Fraud case database: {cases_file}')\n",
        "print(f'   ✅ Vector database: {VECTOR_DB_PATH}')\n",
        "print(f'   ✅ Sample explanations: {explanations_file}')\n",
        "print(f'   ✅ Batch results: {explained_file}')\n",
        "print(f'   ✅ HTML report: {report_path}')\n",
        "print(f'   ✅ Results summary: {results_file}')\n",
        "\n",
        "print(f'\\n📝 Key Features:')\n",
        "print(f'   • Case-based reasoning with vector similarity search')\n",
        "print(f'   • Natural language explanations for fraud predictions')\n",
        "print(f'   • Multi-modal feature integration (graph + sequence + transaction)')\n",
        "print(f'   • Scalable RAG architecture for production deployment')\n",
        "\n",
        "print(f'\\n🚀 Next Steps:')\n",
        "print(f'   1. Integrate with production fraud detection pipeline')\n",
        "print(f'   2. Add LLM for more sophisticated explanations (optional)')\n",
        "print(f'   3. Expand fraud case database with real-world examples')\n",
        "print(f'   4. Deploy as REST API endpoint')\n",
        "print(f'   5. Create real-time explanation dashboard')\n",
        "\n",
        "if RUNNING_ON_KAGGLE:\n",
        "    print(f'\\n💾 Kaggle Users:')\n",
        "    print(f'   - All outputs saved to /kaggle/working/')\n",
        "    print(f'   - Download before session ends')\n",
        "    print(f'   - Vector database can be reused in future sessions')\n",
        "\n",
        "print('\\n' + '='*70)\n",
        "print('✅ NOTEBOOK 06 COMPLETE - EXPLAINABLE AI READY!')\n",
        "print('='*70)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}