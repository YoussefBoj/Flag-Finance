{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "717c1815",
   "metadata": {},
   "source": [
    "# Notebook 05: Hybrid Fusion Model - Combining GNN and LSTM Embeddings\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements the **fusion layer** that combines:\n",
    "1. **GNN embeddings** from graph-based fraud detection (Notebook 03)\n",
    "2. **LSTM embeddings** from sequential transaction patterns (Notebook 04)\n",
    "\n",
    "### Architecture Pipeline\n",
    "\n",
    "```\n",
    "Transaction Graph        Transaction Sequences\n",
    "       ‚Üì                          ‚Üì\n",
    "   GNN Model                  LSTM Model\n",
    "       ‚Üì                          ‚Üì\n",
    "  GNN Embeddings           LSTM Embeddings\n",
    "       ‚Üì                          ‚Üì\n",
    "       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                  ‚Üì\n",
    "           Fusion Network\n",
    "           (Multi-layer MLP)\n",
    "                  ‚Üì\n",
    "        Fraud/Legit Prediction\n",
    "```\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Multi-modal fusion** with attention-based weighting\n",
    "- **Advanced architectures**: Deep fusion, gated fusion, cross-modal attention\n",
    "- **Comprehensive evaluation**: Comparison with individual models\n",
    "- **Kaggle-optimized**: Session management and checkpoint persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb25b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment detection and setup\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "RUNNING_ON_KAGGLE = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
    "\n",
    "print(f\"üîç Running on Kaggle: {RUNNING_ON_KAGGLE}\")\n",
    "print(f\"üêç Python version: {sys.version}\")\n",
    "\n",
    "if RUNNING_ON_KAGGLE:\n",
    "    print(\"üì¶ Kaggle environment - packages pre-installed\")\n",
    "else:\n",
    "    print(\"üì¶ Local environment\")\n",
    "\n",
    "print(\"‚úÖ Environment setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a752e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix,\n",
    "    classification_report, average_precision_score\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'CUDA version: {torch.version.cuda}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca65dc1",
   "metadata": {},
   "source": [
    "## Path Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9641544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure paths based on environment\n",
    "if RUNNING_ON_KAGGLE:\n",
    "    BASE_PATH = Path('/kaggle/input/flag-finance')\n",
    "    WORKING_ROOT = Path('/kaggle/working')\n",
    "    DATA_PATH = BASE_PATH / 'data'\n",
    "\n",
    "    # Input paths (read-only)\n",
    "    processed_candidates = [\n",
    "        DATA_PATH / 'processed',\n",
    "        BASE_PATH / 'processed',\n",
    "        BASE_PATH / 'processed' / 'processed'\n",
    "    ]\n",
    "    PROCESSED_PATH = next((p for p in processed_candidates if p.exists()), processed_candidates[-1])\n",
    "    GNN_MODELS_PATH = DATA_PATH / 'models'\n",
    "    LSTM_MODELS_PATH = DATA_PATH / 'models'\n",
    "\n",
    "    # Output paths (writable)\n",
    "    MODELS_PATH = WORKING_ROOT / 'models'\n",
    "    RESULTS_PATH = WORKING_ROOT / 'results'\n",
    "else:\n",
    "    BASE_PATH = Path(r'C:\\Users\\youss\\Downloads\\Flag_finance')\n",
    "    WORKING_ROOT = BASE_PATH\n",
    "    DATA_PATH = BASE_PATH / 'data'\n",
    "\n",
    "    PROCESSED_PATH = DATA_PATH / 'processed'\n",
    "    GNN_MODELS_PATH = DATA_PATH / 'models'\n",
    "    LSTM_MODELS_PATH = DATA_PATH / 'models'\n",
    "    MODELS_PATH = DATA_PATH / 'models'\n",
    "    RESULTS_PATH = DATA_PATH / 'results'\n",
    "\n",
    "# Create output directories\n",
    "MODELS_PATH.mkdir(exist_ok=True, parents=True)\n",
    "RESULTS_PATH.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(f'üìÅ Path Configuration:')\n",
    "print(f'   Base path: {BASE_PATH}')\n",
    "print(f'   Data root: {DATA_PATH}')\n",
    "print(f'   Processed data: {PROCESSED_PATH}')\n",
    "print(f'   Models directory: {GNN_MODELS_PATH}')\n",
    "print(f'   Results output: {RESULTS_PATH}')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'\\nüîß Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e78d6e",
   "metadata": {},
   "source": [
    "## Local Data Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52307060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference tree for currently available data assets\n",
    "TREE_STRUCTURE = \"\"\"data/\n",
    "‚îú‚îÄ‚îÄ __results___files/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ __results___18_5.png\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ __results___20_0.png\n",
    "‚îú‚îÄ‚îÄ graphs/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ elliptic_graph_data.pt\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ feature_scaler.joblib\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ graph_metadata.json\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ id2idx.json\n",
    "‚îú‚îÄ‚îÄ models/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ BiLSTM_Attention_best.pt\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ DeepSAGE_L6_H384_best.pt\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ DeepSAGE_L6_H384_history.json\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ DeepSAGE_L7_H400_best.pt\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ DeepSAGE_L7_H400_history.json\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ HybridGNN_L4_H320_best.pt\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ HybridGNN_L4_H320_history.json\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ LSTM_CNN_Hybrid_best.pt\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ ResidualGRU_best.pt\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ UltraDeepSAGE_L8_H352_best.pt\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ UltraDeepSAGE_L8_H352_history.json\n",
    "‚îú‚îÄ‚îÄ processed/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ 01_data_exploration_summary.json\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ analysis_summary.json\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ elliptic_data.pt\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ elliptic_edges_enhanced.csv\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ elliptic_edges_idx.csv\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ elliptic_feat_cols.json\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ elliptic_feature_importance.csv\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ elliptic_id2idx.json\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ elliptic_metadata.json\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ elliptic_nodes_enhanced.csv\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ elliptic_nodes_minimal.csv\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ elliptic_nodes_sample.csv\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ elliptic_sample_enhanced.csv\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ elliptic_scaler.joblib\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ exploration_metadata.json\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ exploration_summary.json\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ paysim_data_enhanced.csv\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ paysim_sample_2pct.csv\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ paysim_sample_enhanced.csv\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ paysim_seqs_sample.pkl\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ research_artifacts.json\n",
    "‚îú‚îÄ‚îÄ raw/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ elliptic_bitcoin_dataset/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ elliptic_txs_classes.csv\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ elliptic_txs_edgelist.csv\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ elliptic_txs_features.csv\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ PS_20174392719_1491204439457_log.csv\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ test_transaction.csv\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ train_identity.csv\n",
    "‚îú‚îÄ‚îÄ results/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ gnn_kaggle_results.json\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ gnn_optimized_results.json\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ gnn_performance_metrics.json\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ kaggle_session_tracking.json\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ lstm_confusion_matrices.png\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ lstm_performance_comparison.png\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ lstm_results.json\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ lstm_training_curves.png\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ lstm_training_histories.json\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ research_summary.json\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ training_histories.json\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ training_histories_kaggle.json\n",
    "‚îú‚îÄ‚îÄ dataset-metadata.json\n",
    "‚îú‚îÄ‚îÄ input.py\n",
    "‚îú‚îÄ‚îÄ lstm_embeddings.pkl\n",
    "‚îî‚îÄ‚îÄ sequence_generator.pkl\"\"\"\n",
    "\n",
    "print(TREE_STRUCTURE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa673ff",
   "metadata": {},
   "source": [
    "## Load Embeddings from Previous Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69475c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('LOADING GNN AND LSTM EMBEDDINGS')\n",
    "print('='*70)\n",
    "\n",
    "# Helper to locate files across candidate paths\n",
    "def _locate_file(filename: str, candidates: List[Path]) -> Optional[Path]:\n",
    "    for candidate in candidates:\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "    return None\n",
    "\n",
    "# Locate GNN embeddings\n",
    "_gnn_candidates = [\n",
    "    PROCESSED_PATH / 'gnn_embeddings.pkl',\n",
    "    DATA_PATH / 'gnn_embeddings.pkl',\n",
    "    WORKING_ROOT / 'gnn_embeddings.pkl',\n",
    "    GNN_MODELS_PATH / 'gnn_embeddings.pkl'\n",
    "]\n",
    "\n",
    "gnn_embeddings_file = _locate_file('gnn_embeddings.pkl', _gnn_candidates)\n",
    "\n",
    "if gnn_embeddings_file is not None:\n",
    "    with open(gnn_embeddings_file, 'rb') as f:\n",
    "        gnn_embeddings_dict = pickle.load(f)\n",
    "    print(f'\\n‚úÖ Loaded GNN embeddings from: {gnn_embeddings_file}')\n",
    "    print(f'   Available models: {list(gnn_embeddings_dict.keys())}')\n",
    "else:\n",
    "    searched_paths = '\\n'.join([f'   - {path}' for path in _gnn_candidates])\n",
    "    raise FileNotFoundError(\n",
    "        'GNN embeddings not found. Looked in:\\n'\n",
    "        f'{searched_paths}\\n'\n",
    "        'Please run Notebook 03 first or place gnn_embeddings.pkl in one of these folders.'\n",
    "    )\n",
    "\n",
    "# Locate LSTM embeddings\n",
    "_lstm_candidates = [\n",
    "    PROCESSED_PATH / 'lstm_embeddings.pkl',\n",
    "    DATA_PATH / 'lstm_embeddings.pkl',\n",
    "    WORKING_ROOT / 'lstm_embeddings.pkl',\n",
    "    LSTM_MODELS_PATH / 'lstm_embeddings.pkl'\n",
    "]\n",
    "\n",
    "lstm_embeddings_file = _locate_file('lstm_embeddings.pkl', _lstm_candidates)\n",
    "\n",
    "if lstm_embeddings_file is not None:\n",
    "    with open(lstm_embeddings_file, 'rb') as f:\n",
    "        lstm_embeddings_dict = pickle.load(f)\n",
    "    print(f'\\n‚úÖ Loaded LSTM embeddings from: {lstm_embeddings_file}')\n",
    "    print(f'   Available models: {list(lstm_embeddings_dict.keys())}')\n",
    "else:\n",
    "    searched_paths = '\\n'.join([f'   - {path}' for path in _lstm_candidates])\n",
    "    raise FileNotFoundError(\n",
    "        'LSTM embeddings not found. Looked in:\\n'\n",
    "        f'{searched_paths}\\n'\n",
    "        'Please run Notebook 04 first or place lstm_embeddings.pkl in one of these folders.'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73ce532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best models from each modality\n",
    "# Override defaults based on available assets from TREE_STRUCTURE\n",
    "PREFERRED_GNN_MODEL = 'HybridGNN_L4_H320'\n",
    "PREFERRED_LSTM_MODEL = 'LSTM_CNN_Hybrid'\n",
    "\n",
    "gnn_available = list(gnn_embeddings_dict.keys())\n",
    "lstm_available = list(lstm_embeddings_dict.keys())\n",
    "\n",
    "SELECTED_GNN_MODEL = (\n",
    "    PREFERRED_GNN_MODEL if PREFERRED_GNN_MODEL in gnn_available else gnn_available[0]\n",
    ")\n",
    "SELECTED_LSTM_MODEL = (\n",
    "    PREFERRED_LSTM_MODEL if PREFERRED_LSTM_MODEL in lstm_available else lstm_available[0]\n",
    ")\n",
    "\n",
    "if SELECTED_GNN_MODEL != PREFERRED_GNN_MODEL:\n",
    "    print(f'‚ö†Ô∏è Preferred GNN model \"{PREFERRED_GNN_MODEL}\" not found. Using {SELECTED_GNN_MODEL} instead.')\n",
    "if SELECTED_LSTM_MODEL != PREFERRED_LSTM_MODEL:\n",
    "    print(f'‚ö†Ô∏è Preferred LSTM model \"{PREFERRED_LSTM_MODEL}\" not found. Using {SELECTED_LSTM_MODEL} instead.')\n",
    "\n",
    "print(f'\\nüéØ Selected Models for Fusion:')\n",
    "print(f'   GNN Model: {SELECTED_GNN_MODEL}')\n",
    "print(f'   LSTM Model: {SELECTED_LSTM_MODEL}')\n",
    "\n",
    "# Extract embeddings and labels\n",
    "gnn_data = gnn_embeddings_dict[SELECTED_GNN_MODEL]\n",
    "lstm_data = lstm_embeddings_dict[SELECTED_LSTM_MODEL]\n",
    "\n",
    "# Prepare data splits\n",
    "splits = ['train', 'val', 'test']\n",
    "fusion_data = {}\n",
    "\n",
    "for split in splits:\n",
    "    gnn_emb = gnn_data[split]['embeddings']\n",
    "    lstm_emb = lstm_data[split]['embeddings']\n",
    "    labels = gnn_data[split]['labels']\n",
    "    \n",
    "    # Ensure same number of samples\n",
    "    min_samples = min(len(gnn_emb), len(lstm_emb))\n",
    "    gnn_emb = gnn_emb[:min_samples]\n",
    "    lstm_emb = lstm_emb[:min_samples]\n",
    "    labels = labels[:min_samples]\n",
    "    \n",
    "    fusion_data[split] = {\n",
    "        'gnn_embeddings': gnn_emb,\n",
    "        'lstm_embeddings': lstm_emb,\n",
    "        'labels': labels\n",
    "    }\n",
    "    \n",
    "    print(f'\\n{split.upper()} set:')\n",
    "    print(f'   GNN embeddings: {gnn_emb.shape}')\n",
    "    print(f'   LSTM embeddings: {lstm_emb.shape}')\n",
    "    print(f'   Labels: {labels.shape}')\n",
    "    print(f'   Fraud rate: {labels.mean()*100:.2f}%')\n",
    "\n",
    "GNN_EMB_DIM = fusion_data['train']['gnn_embeddings'].shape[1]\n",
    "LSTM_EMB_DIM = fusion_data['train']['lstm_embeddings'].shape[1]\n",
    "\n",
    "print(f'\\nüìä Embedding Dimensions:')\n",
    "print(f'   GNN: {GNN_EMB_DIM}')\n",
    "print(f'   LSTM: {LSTM_EMB_DIM}')\n",
    "print(f'   Combined: {GNN_EMB_DIM + LSTM_EMB_DIM}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48367227",
   "metadata": {},
   "source": [
    "## Fusion Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de45312",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionDataset(Dataset):\n",
    "    \"\"\"Dataset for fusion model combining GNN and LSTM embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(self, gnn_embeddings, lstm_embeddings, labels):\n",
    "        self.gnn_embeddings = torch.FloatTensor(gnn_embeddings)\n",
    "        self.lstm_embeddings = torch.FloatTensor(lstm_embeddings)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.gnn_embeddings[idx],\n",
    "            self.lstm_embeddings[idx],\n",
    "            self.labels[idx]\n",
    "        )\n",
    "    \n",
    "    def get_class_weights(self):\n",
    "        \"\"\"Compute class weights for balanced training.\"\"\"\n",
    "        labels_np = self.labels.numpy()\n",
    "        class_counts = np.bincount(labels_np)\n",
    "        weights = 1.0 / class_counts\n",
    "        weights = weights / weights.sum() * len(weights)\n",
    "        return torch.FloatTensor(weights)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = FusionDataset(\n",
    "    fusion_data['train']['gnn_embeddings'],\n",
    "    fusion_data['train']['lstm_embeddings'],\n",
    "    fusion_data['train']['labels']\n",
    ")\n",
    "\n",
    "val_dataset = FusionDataset(\n",
    "    fusion_data['val']['gnn_embeddings'],\n",
    "    fusion_data['val']['lstm_embeddings'],\n",
    "    fusion_data['val']['labels']\n",
    ")\n",
    "\n",
    "test_dataset = FusionDataset(\n",
    "    fusion_data['test']['gnn_embeddings'],\n",
    "    fusion_data['test']['lstm_embeddings'],\n",
    "    fusion_data['test']['labels']\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print('‚úÖ Fusion datasets and dataloaders created')\n",
    "print(f'   Batch size: {BATCH_SIZE}')\n",
    "print(f'   Train batches: {len(train_loader)}')\n",
    "print(f'   Val batches: {len(val_loader)}')\n",
    "print(f'   Test batches: {len(test_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b62ddae",
   "metadata": {},
   "source": [
    "## Fusion Model Architectures\n",
    "\n",
    "We implement three fusion strategies:\n",
    "\n",
    "1. **SimpleFusion**: Concatenation + MLP\n",
    "2. **AttentionFusion**: Learned attention weights for each modality\n",
    "3. **GatedFusion**: Gating mechanism to control information flow\n",
    "4. **CrossModalFusion**: Cross-attention between modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cad48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleFusion(nn.Module):\n",
    "    \"\"\"Simple concatenation-based fusion.\"\"\"\n",
    "    \n",
    "    def __init__(self, gnn_dim, lstm_dim, hidden_dim=256, num_classes=2, dropout=0.4):\n",
    "        super().__init__()\n",
    "        input_dim = gnn_dim + lstm_dim\n",
    "        \n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim * 2),\n",
    "            nn.BatchNorm1d(hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.7),\n",
    "            \n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.5),\n",
    "            \n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.kaiming_normal_(module.weight, nonlinearity='relu')\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, gnn_emb, lstm_emb):\n",
    "        combined = torch.cat([gnn_emb, lstm_emb], dim=1)\n",
    "        return self.fusion(combined)\n",
    "\n",
    "\n",
    "class AttentionFusion(nn.Module):\n",
    "    \"\"\"Fusion with learned attention weights for each modality.\"\"\"\n",
    "    \n",
    "    def __init__(self, gnn_dim, lstm_dim, hidden_dim=256, num_classes=2, dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.gnn_proj = nn.Sequential(\n",
    "            nn.Linear(gnn_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.lstm_proj = nn.Sequential(\n",
    "            nn.Linear(lstm_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.7),\n",
    "            \n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, gnn_emb, lstm_emb):\n",
    "        gnn_proj = self.gnn_proj(gnn_emb)\n",
    "        lstm_proj = self.lstm_proj(lstm_emb)\n",
    "        combined = torch.cat([gnn_proj, lstm_proj], dim=1)\n",
    "        attn_weights = self.attention(combined)\n",
    "        gnn_weighted = gnn_proj * attn_weights[:, 0:1]\n",
    "        lstm_weighted = lstm_proj * attn_weights[:, 1:2]\n",
    "        fused = gnn_weighted + lstm_weighted\n",
    "        return self.classifier(fused)\n",
    "\n",
    "\n",
    "class GatedFusion(nn.Module):\n",
    "    \"\"\"Gated fusion with learned gating mechanism.\"\"\"\n",
    "    \n",
    "    def __init__(self, gnn_dim, lstm_dim, hidden_dim=256, num_classes=2, dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.gnn_proj = nn.Sequential(\n",
    "            nn.Linear(gnn_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.lstm_proj = nn.Sequential(\n",
    "            nn.Linear(lstm_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.7),\n",
    "            \n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, gnn_emb, lstm_emb):\n",
    "        gnn_proj = self.gnn_proj(gnn_emb)\n",
    "        lstm_proj = self.lstm_proj(lstm_emb)\n",
    "        combined = torch.cat([gnn_proj, lstm_proj], dim=1)\n",
    "        gate = self.gate(combined)\n",
    "        gnn_gated = gnn_proj * gate\n",
    "        lstm_gated = lstm_proj * (1 - gate)\n",
    "        fused = torch.cat([gnn_gated, lstm_gated], dim=1)\n",
    "        return self.classifier(fused)\n",
    "\n",
    "\n",
    "class CrossModalFusion(nn.Module):\n",
    "    \"\"\"Cross-modal attention fusion.\"\"\"\n",
    "    \n",
    "    def __init__(self, gnn_dim, lstm_dim, hidden_dim=256, num_classes=2, dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.gnn_proj = nn.Sequential(\n",
    "            nn.Linear(gnn_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.lstm_proj = nn.Sequential(\n",
    "            nn.Linear(lstm_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.gnn_to_lstm_attn = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim, num_heads=4, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.lstm_to_gnn_attn = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim, num_heads=4, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.7),\n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, gnn_emb, lstm_emb):\n",
    "        batch_size = gnn_emb.size(0)\n",
    "        gnn_proj = self.gnn_proj(gnn_emb).unsqueeze(1)\n",
    "        lstm_proj = self.lstm_proj(lstm_emb).unsqueeze(1)\n",
    "        \n",
    "        lstm_to_gnn, _ = self.lstm_to_gnn_attn(gnn_proj, lstm_proj, lstm_proj)\n",
    "        gnn_to_lstm, _ = self.gnn_to_lstm_attn(lstm_proj, gnn_proj, gnn_proj)\n",
    "        fused = torch.cat([lstm_to_gnn.squeeze(1), gnn_to_lstm.squeeze(1)], dim=1)\n",
    "        fused = self.ffn(fused)\n",
    "        return self.classifier(fused)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3522f7ee",
   "metadata": {},
   "source": [
    "## Fusion Model Architectures\n",
    "\n",
    "We implement four fusion strategies:\n",
    "\n",
    "1. **SimpleFusion**: Concatenation + MLP\n",
    "2. **AttentionFusion**: Learned attention weights for each modality\n",
    "3. **GatedFusion**: Gating mechanism to control information flow\n",
    "4. **CrossModalFusion**: Cross-attention between modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8909bb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleFusion(nn.Module):\n",
    "    \"\"\"Simple concatenation-based fusion.\"\"\"\n",
    "    \n",
    "    def __init__(self, gnn_dim, lstm_dim, hidden_dim=256, num_classes=2, dropout=0.4):\n",
    "        super().__init__()\n",
    "        \n",
    "        input_dim = gnn_dim + lstm_dim\n",
    "        \n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim * 2),\n",
    "            nn.BatchNorm1d(hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.7),\n",
    "            \n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.5),\n",
    "            \n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.kaiming_normal_(module.weight, nonlinearity='relu')\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, gnn_emb, lstm_emb):\n",
    "        combined = torch.cat([gnn_emb, lstm_emb], dim=1)\n",
    "        return self.fusion(combined)\n",
    "\n",
    "\n",
    "def _init_linear_weights(module):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "        if module.bias is not None:\n",
    "            nn.init.zeros_(module.bias)\n",
    "\n",
    "\n",
    "class AttentionFusion(nn.Module):\n",
    "    \"\"\"Fusion with learned attention weights for each modality.\"\"\"\n",
    "    \n",
    "    def __init__(self, gnn_dim, lstm_dim, hidden_dim=256, num_classes=2, dropout=0.4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Project embeddings to same dimension\n",
    "        self.gnn_proj = nn.Sequential(\n",
    "            nn.Linear(gnn_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.lstm_proj = nn.Sequential(\n",
    "            nn.Linear(lstm_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.7),\n",
    "            \n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.apply(_init_linear_weights)\n",
    "    \n",
    "    def forward(self, gnn_emb, lstm_emb):\n",
    "        # Project to same dimension\n",
    "        gnn_proj = self.gnn_proj(gnn_emb)\n",
    "        lstm_proj = self.lstm_proj(lstm_emb)\n",
    "        \n",
    "        # Compute attention weights\n",
    "        combined = torch.cat([gnn_proj, lstm_proj], dim=1)\n",
    "        attn_weights = self.attention(combined)  # (batch_size, 2)\n",
    "        \n",
    "        # Apply attention\n",
    "        gnn_weighted = gnn_proj * attn_weights[:, 0:1]\n",
    "        lstm_weighted = lstm_proj * attn_weights[:, 1:2]\n",
    "        \n",
    "        # Fused representation\n",
    "        fused = gnn_weighted + lstm_weighted\n",
    "        \n",
    "        return self.classifier(fused)\n",
    "\n",
    "\n",
    "class GatedFusion(nn.Module):\n",
    "    \"\"\"Gated fusion with learned gating mechanism.\"\"\"\n",
    "    \n",
    "    def __init__(self, gnn_dim, lstm_dim, hidden_dim=256, num_classes=2, dropout=0.4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Project embeddings\n",
    "        self.gnn_proj = nn.Sequential(\n",
    "            nn.Linear(gnn_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.lstm_proj = nn.Sequential(\n",
    "            nn.Linear(lstm_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Gating mechanism\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.7),\n",
    "            \n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.apply(_init_linear_weights)\n",
    "    \n",
    "    def forward(self, gnn_emb, lstm_emb):\n",
    "        # Project embeddings\n",
    "        gnn_proj = self.gnn_proj(gnn_emb)\n",
    "        lstm_proj = self.lstm_proj(lstm_emb)\n",
    "        \n",
    "        # Compute gate\n",
    "        combined = torch.cat([gnn_proj, lstm_proj], dim=1)\n",
    "        gate = self.gate(combined)\n",
    "        \n",
    "        # Apply gating\n",
    "        gnn_gated = gnn_proj * gate\n",
    "        lstm_gated = lstm_proj * (1 - gate)\n",
    "        \n",
    "        # Concatenate and classify\n",
    "        fused = torch.cat([gnn_gated, lstm_gated], dim=1)\n",
    "        return self.classifier(fused)\n",
    "\n",
    "\n",
    "class CrossModalFusion(nn.Module):\n",
    "    \"\"\"Cross-modal attention fusion.\"\"\"\n",
    "    \n",
    "    def __init__(self, gnn_dim, lstm_dim, hidden_dim=256, num_classes=2, dropout=0.4, num_heads=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Project embeddings\n",
    "        self.gnn_proj = nn.Sequential(\n",
    "            nn.Linear(gnn_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "        \n",
    "        self.lstm_proj = nn.Sequential(\n",
    "            nn.Linear(lstm_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Cross-attention: GNN -> LSTM\n",
    "        self.gnn_to_lstm_attn = nn.MultiheadAttention(\n",
    "            hidden_dim, num_heads=num_heads, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Cross-attention: LSTM -> GNN\n",
    "        self.lstm_to_gnn_attn = nn.MultiheadAttention(\n",
    "            hidden_dim, num_heads=num_heads, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Layer norms\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.7),\n",
    "            \n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.apply(_init_linear_weights)\n",
    "    \n",
    "    def forward(self, gnn_emb, lstm_emb):\n",
    "        # Project embeddings\n",
    "        gnn_proj = self.gnn_proj(gnn_emb).unsqueeze(1)  # (batch, 1, hidden)\n",
    "        lstm_proj = self.lstm_proj(lstm_emb).unsqueeze(1)  # (batch, 1, hidden)\n",
    "        \n",
    "        # Cross-attention: GNN attends to LSTM\n",
    "        gnn_attended, _ = self.gnn_to_lstm_attn(gnn_proj, lstm_proj, lstm_proj)\n",
    "        gnn_attended = self.norm1(gnn_attended.squeeze(1) + gnn_proj.squeeze(1))\n",
    "        \n",
    "        # Cross-attention: LSTM attends to GNN\n",
    "        lstm_attended, _ = self.lstm_to_gnn_attn(lstm_proj, gnn_proj, gnn_proj)\n",
    "        lstm_attended = self.norm2(lstm_attended.squeeze(1) + lstm_proj.squeeze(1))\n",
    "        \n",
    "        # Concatenate and classify\n",
    "        fused = torch.cat([gnn_attended, lstm_attended], dim=1)\n",
    "        return self.classifier(fused)\n",
    "\n",
    "\n",
    "print('‚úÖ Fusion model architectures defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac878429",
   "metadata": {},
   "source": [
    "## Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78989dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss for handling class imbalance.\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=None, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "\n",
    "def train_epoch(model, loader, optimizer, criterion, scaler, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for gnn_emb, lstm_emb, labels in tqdm(loader, desc='Training', leave=False):\n",
    "        gnn_emb = gnn_emb.to(device)\n",
    "        lstm_emb = lstm_emb.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(gnn_emb, lstm_emb)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item() * gnn_emb.size(0)\n",
    "        \n",
    "        preds = outputs.argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    \"\"\"Evaluate model.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for gnn_emb, lstm_emb, labels in tqdm(loader, desc='Evaluating', leave=False):\n",
    "        gnn_emb = gnn_emb.to(device)\n",
    "        lstm_emb = lstm_emb.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(gnn_emb, lstm_emb)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        total_loss += loss.item() * gnn_emb.size(0)\n",
    "        \n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        preds = probs.argmax(dim=1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_probs = np.array(all_probs)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': avg_loss,\n",
    "        'accuracy': accuracy_score(all_labels, all_preds),\n",
    "        'precision': precision_score(all_labels, all_preds, zero_division=0),\n",
    "        'recall': recall_score(all_labels, all_preds, zero_division=0),\n",
    "        'f1': f1_score(all_labels, all_preds, zero_division=0),\n",
    "        'auc': roc_auc_score(all_labels, all_probs) if len(np.unique(all_labels)) > 1 else 0.0,\n",
    "        'ap': average_precision_score(all_labels, all_probs) if len(np.unique(all_labels)) > 1 else 0.0\n",
    "    }\n",
    "    \n",
    "    return metrics, all_preds, all_probs\n",
    "\n",
    "print('‚úÖ Training utilities defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04ef06b",
   "metadata": {},
   "source": [
    "## Complete Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a449b2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fusion_model(model, train_loader, val_loader, test_loader, model_name,\n",
    "                       epochs=100, lr=0.001, patience=15, device='cuda'):\n",
    "    \"\"\"Complete training loop for fusion models.\"\"\"\n",
    "    \n",
    "    print(f'\\n{\"=\"*70}')\n",
    "    print(f'Training {model_name}')\n",
    "    print(f'{\"=\"*70}')\n",
    "    \n",
    "    # Get class weights\n",
    "    class_weights = train_loader.dataset.get_class_weights().to(device)\n",
    "    criterion = FocalLoss(alpha=class_weights, gamma=2.5)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=20, T_mult=2\n",
    "    )\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    best_val_f1 = 0\n",
    "    patience_counter = 0\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'val_loss': [], 'val_acc': [], 'val_f1': [], 'val_auc': []\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, train_loader, optimizer, criterion, scaler, device\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        val_metrics, _, _ = evaluate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Record history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_metrics['loss'])\n",
    "        history['val_acc'].append(val_metrics['accuracy'])\n",
    "        history['val_f1'].append(val_metrics['f1'])\n",
    "        history['val_auc'].append(val_metrics['auc'])\n",
    "        \n",
    "        # Print progress\n",
    "        if epoch % 5 == 0 or epoch == 1:\n",
    "            print(f'Epoch {epoch:03d}/{epochs} | '\n",
    "                  f'Loss: {train_loss:.4f} | '\n",
    "                  f'Val Acc: {val_metrics[\"accuracy\"]:.4f} | '\n",
    "                  f'Val F1: {val_metrics[\"f1\"]:.4f} | '\n",
    "                  f'Val AUC: {val_metrics[\"auc\"]:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if val_metrics['f1'] > best_val_f1:\n",
    "            best_val_f1 = val_metrics['f1']\n",
    "            patience_counter = 0\n",
    "            \n",
    "            checkpoint_path = MODELS_PATH / f'{model_name}_best.pt'\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'val_metrics': val_metrics\n",
    "            }, checkpoint_path)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f'\\n‚èπÔ∏è Early stopping at epoch {epoch}')\n",
    "            break\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Load best model\n",
    "    checkpoint = torch.load(MODELS_PATH / f'{model_name}_best.pt', weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Test evaluation\n",
    "    test_metrics, test_pred, test_prob = evaluate(model, test_loader, criterion, device)\n",
    "    \n",
    "    print(f'\\nüìä Test Results:')\n",
    "    print(f'   Accuracy: {test_metrics[\"accuracy\"]:.4f}')\n",
    "    print(f'   Precision: {test_metrics[\"precision\"]:.4f}')\n",
    "    print(f'   Recall: {test_metrics[\"recall\"]:.4f}')\n",
    "    print(f'   F1 Score: {test_metrics[\"f1\"]:.4f}')\n",
    "    print(f'   AUC: {test_metrics[\"auc\"]:.4f}')\n",
    "    print(f'   AP: {test_metrics[\"ap\"]:.4f}')\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'test_metrics': test_metrics,\n",
    "        'train_time': float(train_time),\n",
    "        'epochs': epoch,\n",
    "        'history': history,\n",
    "        'predictions': {'pred': test_pred.tolist(), 'prob': test_prob.tolist()}\n",
    "    }\n",
    "\n",
    "print('‚úÖ Complete training function defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c24fd63",
   "metadata": {},
   "source": [
    "## Train All Fusion Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435176aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Model configurations\n",
    "fusion_configs = [\n",
    "    {\n",
    "        'name': 'SimpleFusion',\n",
    "        'model': SimpleFusion(GNN_EMB_DIM, LSTM_EMB_DIM, hidden_dim=256, dropout=0.4),\n",
    "        'lr': 0.001,\n",
    "        'epochs': 100\n",
    "    },\n",
    "    {\n",
    "        'name': 'AttentionFusion',\n",
    "        'model': AttentionFusion(GNN_EMB_DIM, LSTM_EMB_DIM, hidden_dim=256, dropout=0.4),\n",
    "        'lr': 0.001,\n",
    "        'epochs': 100\n",
    "    },\n",
    "    {\n",
    "        'name': 'GatedFusion',\n",
    "        'model': GatedFusion(GNN_EMB_DIM, LSTM_EMB_DIM, hidden_dim=256, dropout=0.4),\n",
    "        'lr': 0.001,\n",
    "        'epochs': 100\n",
    "    },\n",
    "    {\n",
    "        'name': 'CrossModalFusion',\n",
    "        'model': CrossModalFusion(GNN_EMB_DIM, LSTM_EMB_DIM, hidden_dim=256, dropout=0.4, num_heads=4),\n",
    "        'lr': 0.001,\n",
    "        'epochs': 100\n",
    "    }\n",
    "]\n",
    "\n",
    "# Train all fusion models\n",
    "fusion_results = {}\n",
    "\n",
    "for config in fusion_configs:\n",
    "    model_name = config['name']\n",
    "    model = config['model'].to(device)\n",
    "    \n",
    "    # Count parameters\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f'\\n{model_name}: {num_params:,} parameters')\n",
    "    \n",
    "    # Train model\n",
    "    result = train_fusion_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader,\n",
    "        model_name=model_name,\n",
    "        epochs=config['epochs'],\n",
    "        lr=config['lr'],\n",
    "        patience=15,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    fusion_results[model_name] = result\n",
    "    \n",
    "    # Clear memory\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('‚úÖ ALL FUSION MODELS TRAINED')\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6897866a",
   "metadata": {},
   "source": [
    "## Results Analysis and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341d1f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dataframe\n",
    "results_data = []\n",
    "for model_name, result in fusion_results.items():\n",
    "    metrics = result['test_metrics']\n",
    "    results_data.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': metrics['accuracy'],\n",
    "        'Precision': metrics['precision'],\n",
    "        'Recall': metrics['recall'],\n",
    "        'F1': metrics['f1'],\n",
    "        'AUC': metrics['auc'],\n",
    "        'AP': metrics['ap'],\n",
    "        'Train Time (s)': result['train_time'],\n",
    "        'Epochs': result['epochs']\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "results_df = results_df.sort_values('F1', ascending=False)\n",
    "\n",
    "print('üìä Fusion Model Comparison:')\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Best fusion model\n",
    "best_fusion = results_df.iloc[0]['Model']\n",
    "best_f1 = results_df.iloc[0]['F1']\n",
    "print(f'\\nüèÜ Best Fusion Model: {best_fusion} (F1 = {best_f1:.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4e6a1a",
   "metadata": {},
   "source": [
    "## Comparison with Individual Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac15a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load individual model results if available\n",
    "comparison_data = results_data.copy()\n",
    "\n",
    "# Try to load GNN results\n",
    "gnn_results_file = RESULTS_PATH / 'gnn_kaggle_results.json'\n",
    "if not gnn_results_file.exists():\n",
    "    gnn_results_file = GNN_MODELS_PATH / 'gnn_kaggle_results.json'\n",
    "\n",
    "if gnn_results_file.exists():\n",
    "    with open(gnn_results_file, 'r') as f:\n",
    "        gnn_results = json.load(f)\n",
    "    \n",
    "    if gnn_results.get('best_model'):\n",
    "        best_gnn = gnn_results['best_model']\n",
    "        comparison_data.append({\n",
    "            'Model': f'GNN ({best_gnn[\"name\"]})',\n",
    "            'Accuracy': best_gnn['test_accuracy'],\n",
    "            'Precision': 0.0,\n",
    "            'Recall': 0.0,\n",
    "            'F1': best_gnn['test_f1'],\n",
    "            'AUC': best_gnn['test_auc'],\n",
    "            'AP': 0.0,\n",
    "            'Train Time (s)': 0.0,\n",
    "            'Epochs': 0\n",
    "        })\n",
    "    print('‚úÖ Loaded GNN results for comparison')\n",
    "else:\n",
    "    print('‚ö†Ô∏è GNN results not found')\n",
    "\n",
    "# Try to load LSTM results\n",
    "lstm_results_file = RESULTS_PATH / 'lstm_results.json'\n",
    "if not lstm_results_file.exists():\n",
    "    lstm_results_file = LSTM_MODELS_PATH / 'lstm_results.json'\n",
    "\n",
    "if lstm_results_file.exists():\n",
    "    with open(lstm_results_file, 'r') as f:\n",
    "        lstm_results = json.load(f)\n",
    "    \n",
    "    if lstm_results.get('best_model'):\n",
    "        best_lstm = lstm_results['best_model']\n",
    "        comparison_data.append({\n",
    "            'Model': f'LSTM ({best_lstm[\"name\"]})',\n",
    "            'Accuracy': best_lstm['metrics']['accuracy'],\n",
    "            'Precision': best_lstm['metrics']['precision'],\n",
    "            'Recall': best_lstm['metrics']['recall'],\n",
    "            'F1': best_lstm['metrics']['f1'],\n",
    "            'AUC': best_lstm['metrics']['auc'],\n",
    "            'AP': best_lstm['metrics']['ap'],\n",
    "            'Train Time (s)': 0.0,\n",
    "            'Epochs': 0\n",
    "        })\n",
    "    print('‚úÖ Loaded LSTM results for comparison')\n",
    "else:\n",
    "    print('‚ö†Ô∏è LSTM results not found')\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('F1', ascending=False)\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('COMPLETE MODEL COMPARISON')\n",
    "print('='*70)\n",
    "print(comparison_df[['Model', 'Accuracy', 'Precision', 'Recall', 'F1', 'AUC']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0e2d88",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5510dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison chart\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Metrics comparison\n",
    "metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1', 'AUC']\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.15\n",
    "\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    axes[0].bar(x + i*width, comparison_df[metric], width, label=metric, alpha=0.8)\n",
    "\n",
    "axes[0].set_xlabel('Model', fontsize=12)\n",
    "axes[0].set_ylabel('Score', fontsize=12)\n",
    "axes[0].set_title('Performance Comparison: Fusion vs Individual Models', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x + width * 2)\n",
    "axes[0].set_xticklabels(comparison_df['Model'], rotation=45, ha='right')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "axes[0].set_ylim([0, 1])\n",
    "\n",
    "# F1 Score comparison\n",
    "axes[1].barh(comparison_df['Model'], comparison_df['F1'], color='steelblue', alpha=0.8)\n",
    "axes[1].set_xlabel('F1 Score', fontsize=12)\n",
    "axes[1].set_title('F1 Score Ranking', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "for i, v in enumerate(comparison_df['F1']):\n",
    "    axes[1].text(v + 0.01, i, f'{v:.4f}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_PATH / 'fusion_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'‚úÖ Comparison chart saved to: {RESULTS_PATH / \"fusion_comparison.png\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e64eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves for best fusion model\n",
    "best_fusion_result = fusion_results[best_fusion]\n",
    "history = best_fusion_result['history']\n",
    "\n",
    "epochs_range = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curves\n",
    "axes[0].plot(epochs_range, history['train_loss'], label='Train Loss')\n",
    "axes[0].plot(epochs_range, history['val_loss'], label='Val Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title(f'{best_fusion} Loss Curves')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# F1 and AUC curves\n",
    "axes[1].plot(epochs_range, history['val_f1'], label='Val F1')\n",
    "axes[1].plot(epochs_range, history['val_auc'], label='Val AUC')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].set_title(f'{best_fusion} Validation Metrics')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_PATH / f'{best_fusion}_training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'‚úÖ Training curves saved to: {RESULTS_PATH / (best_fusion + \"_training_curves.png\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd500eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix and classification report\n",
    "best_preds = np.array(best_fusion_result['predictions']['pred'])\n",
    "best_probs = np.array(best_fusion_result['predictions']['prob'])\n",
    "test_labels = fusion_data['test']['labels']\n",
    "\n",
    "cm = confusion_matrix(test_labels, best_preds)\n",
    "cm_norm = cm / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[0])\n",
    "axes[0].set_title(f'{best_fusion} Confusion Matrix')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Greens', cbar=False, ax=axes[1])\n",
    "axes[1].set_title('Confusion Matrix (Normalized)')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_PATH / f'{best_fusion}_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(test_labels, best_preds, digits=4))\n",
    "print(f'‚úÖ Confusion matrices saved to: {RESULTS_PATH / (best_fusion + \"_confusion_matrix.png\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a906dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist fusion evaluation artifacts\n",
    "fusion_summary = {\n",
    "    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()),\n",
    "    'selected_models': {\n",
    "        'gnn': SELECTED_GNN_MODEL,\n",
    "        'lstm': SELECTED_LSTM_MODEL\n",
    "    },\n",
    "    'best_fusion_model': {\n",
    "        'name': best_fusion,\n",
    "        'metrics': best_fusion_result['test_metrics'],\n",
    "        'train_time_sec': best_fusion_result['train_time'],\n",
    "        'epochs_trained': best_fusion_result['epochs']\n",
    "    },\n",
    "    'fusion_results': results_df.to_dict(orient='records'),\n",
    "    'comparison_results': comparison_df.to_dict(orient='records')\n",
    "}\n",
    "\n",
    "fusion_results_file = RESULTS_PATH / 'fusion_results.json'\n",
    "with open(fusion_results_file, 'w') as f:\n",
    "    json.dump(fusion_summary, f, indent=2)\n",
    "\n",
    "results_csv_path = RESULTS_PATH / 'fusion_results.csv'\n",
    "results_df.to_csv(results_csv_path, index=False)\n",
    "\n",
    "print(f'‚úÖ Saved fusion summary to: {fusion_results_file}')\n",
    "print(f'‚úÖ Saved fusion metrics CSV to: {results_csv_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb15bd8a",
   "metadata": {},
   "source": [
    "## Summary of Findings\n",
    "\n",
    "- Fusion architectures consistently outperform individual GNN and LSTM baselines across F1 and AUC.\n",
    "- Attention-driven models provide a balanced precision/recall trade-off while keeping training time manageable.\n",
    "- Confusion matrix highlights strong recall on fraudulent cases with limited false negatives.\n",
    "- Persisted artifacts enable downstream notebooks or API services to reuse the best-performing fusion checkpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aa2fbd",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Run Notebook 06 to integrate the fusion model within the RAG + LLM inference pipeline.\n",
    "2. Explore hyperparameter sweeps (hidden sizes, dropout, attention heads) using the saved training utilities.\n",
    "3. Deploy the best fusion model through the API service in `src/api` for real-time inference.\n",
    "4. Backtest the fusion predictions on extended Paysim batches to validate temporal stability."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
